{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2cfd33c-39a4-40b9-b4f7-7251b629a932",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-02T18:51:43.8399051Z",
       "execution_start_time": "2024-11-02T18:51:42.2474146Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "c47e105f-1d82-4e34-9b1c-f7384a784e6d",
       "queued_time": "2024-11-02T18:51:40.8140866Z",
       "session_id": "6b9a1872-50ac-457d-845a-740201bbd234",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 44,
       "statement_ids": [
        44
       ]
      },
      "text/plain": [
       "StatementMeta(, 6b9a1872-50ac-457d-845a-740201bbd234, 44, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------+-----------+-------------------+---------------------+-----------+--------------------+\n",
      "|           IP|                  ID|Variable|Measurement|          Timestamp|EventProcessedUtcTime|PartitionId|EventEnqueuedUtcTime|\n",
      "+-------------+--------------------+--------+-----------+-------------------+---------------------+-----------+--------------------+\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Ta|       6.1C|2024-11-02 15:30:36| 2024-11-02 15:52:...|          1|2024-11-02 15:52:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Ua|     100.0P|2024-11-02 15:30:36| 2024-11-02 15:52:...|          1|2024-11-02 15:52:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Ua|     100.0P|2024-11-02 15:31:16| 2024-11-02 16:17:...|          2|2024-11-02 16:17:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Ta|       6.1C|2024-11-02 15:31:26| 2024-11-02 16:24:...|          3|2024-11-02 16:24:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Pa|     882.8H|2024-11-02 15:31:26| 2024-11-02 16:25:...|          3|2024-11-02 16:25:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Ta|       6.1C|2024-11-02 15:31:36| 2024-11-02 16:29:...|          2|2024-11-02 16:29:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Pa|     882.8H|2024-11-02 15:31:36| 2024-11-02 16:30:...|          2|2024-11-02 16:30:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Ta|       6.2C|2024-11-02 15:30:06| 2024-11-02 15:33:...|          2|2024-11-02 15:33:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Vr|     3.636V|2024-11-02 15:31:23| 2024-11-02 16:20:...|          3|2024-11-02 16:20:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Dm|       168D|2024-11-02 15:31:25| 2024-11-02 16:22:...|          3|2024-11-02 16:22:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Sm|       3.5M|2024-11-02 15:31:25| 2024-11-02 16:22:...|          3|2024-11-02 16:22:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Ua|     100.0P|2024-11-02 15:31:25| 2024-11-02 16:22:...|          1|2024-11-02 16:22:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Rc|      1.07M|2024-11-02 15:31:25| 2024-11-02 16:22:...|          1|2024-11-02 16:22:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Rd|      1800s|2024-11-02 15:31:25| 2024-11-02 16:22:...|          1|2024-11-02 16:22:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Hc|       0.0M|2024-11-02 15:31:25| 2024-11-02 16:23:...|          1|2024-11-02 16:23:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Vh|      23.9V|2024-11-02 15:31:23| 2024-11-02 16:20:...|          2|2024-11-02 16:20:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Dn|       157D|2024-11-02 15:30:25| 2024-11-02 15:44:...|          1|2024-11-02 15:44:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Dm|       167D|2024-11-02 15:30:25| 2024-11-02 15:44:...|          1|2024-11-02 15:44:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Dx|       175D|2024-11-02 15:30:25| 2024-11-02 15:44:...|          1|2024-11-02 15:44:...|\n",
      "|198.202.124.3|HPWREN:LP-WXT536:...|      Sn|       1.2M|2024-11-02 15:30:25| 2024-11-02 15:44:...|          1|2024-11-02 15:44:...|\n",
      "+-------------+--------------------+--------+-----------+-------------------+---------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Número de filas: 680\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "\n",
    "# Crear la sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"Fabric_Lakehouse_Read_bronce\").getOrCreate()\n",
    "\n",
    "# Definir la ruta del archivo Parquet\n",
    "parquet_path = \"Files/bronce/datos.parquet\"\n",
    "\n",
    "# Leer el archivo Parquet\n",
    "df = spark.read.format(\"parquet\").load(parquet_path)\n",
    "\n",
    "# Mostrar los datos leídos\n",
    "df.show()\n",
    "\n",
    "# Contar las filas del DataFrame\n",
    "print(\"Número de filas:\", df.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f74ed3bc-a32f-40d1-afe1-e94aa15f5fb6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-02T18:51:45.3073035Z",
       "execution_start_time": "2024-11-02T18:51:44.4532147Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "76172202-a08e-4881-86d1-d2efea2512e5",
       "queued_time": "2024-11-02T18:51:40.8913659Z",
       "session_id": "6b9a1872-50ac-457d-845a-740201bbd234",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 45,
       "statement_ids": [
        45
       ]
      },
      "text/plain": [
       "StatementMeta(, 6b9a1872-50ac-457d-845a-740201bbd234, 45, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------------+\n",
      "|Variable|Measurement|          Timestamp|\n",
      "+--------+-----------+-------------------+\n",
      "|      Ta|       6.1C|2024-11-02 15:30:36|\n",
      "|      Ua|     100.0P|2024-11-02 15:30:36|\n",
      "|      Ua|     100.0P|2024-11-02 15:31:16|\n",
      "|      Ta|       6.1C|2024-11-02 15:31:26|\n",
      "|      Pa|     882.8H|2024-11-02 15:31:26|\n",
      "|      Ta|       6.1C|2024-11-02 15:31:36|\n",
      "|      Pa|     882.8H|2024-11-02 15:31:36|\n",
      "|      Ta|       6.2C|2024-11-02 15:30:06|\n",
      "|      Vr|     3.636V|2024-11-02 15:31:23|\n",
      "|      Dm|       168D|2024-11-02 15:31:25|\n",
      "|      Sm|       3.5M|2024-11-02 15:31:25|\n",
      "|      Ua|     100.0P|2024-11-02 15:31:25|\n",
      "|      Rc|      1.07M|2024-11-02 15:31:25|\n",
      "|      Rd|      1800s|2024-11-02 15:31:25|\n",
      "|      Hc|       0.0M|2024-11-02 15:31:25|\n",
      "|      Vh|      23.9V|2024-11-02 15:31:23|\n",
      "|      Dn|       157D|2024-11-02 15:30:25|\n",
      "|      Dm|       167D|2024-11-02 15:30:25|\n",
      "|      Dx|       175D|2024-11-02 15:30:25|\n",
      "|      Sn|       1.2M|2024-11-02 15:30:25|\n",
      "+--------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar solo las columnas 'Variable', 'Measurement', y 'Timestamp'\n",
    "df= df.select(\"Variable\", \"Measurement\", \"Timestamp\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c91623c-cedd-4f16-968c-c07b8a180075",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-02T18:51:46.7905906Z",
       "execution_start_time": "2024-11-02T18:51:45.922942Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "61c7ade7-d086-4ed9-8628-db43ac31b3fc",
       "queued_time": "2024-11-02T18:51:40.9577565Z",
       "session_id": "6b9a1872-50ac-457d-845a-740201bbd234",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 46,
       "statement_ids": [
        46
       ]
      },
      "text/plain": [
       "StatementMeta(, 6b9a1872-50ac-457d-845a-740201bbd234, 46, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+-----------+-------------------+\n",
      "|Variable|     nombre_variable|Measurement|Mapped_Unit|          Timestamp|\n",
      "+--------+--------------------+-----------+-----------+-------------------+\n",
      "|      Ta|     Air temperature|       6.1C|         °C|2024-11-02 15:30:36|\n",
      "|      Ua|   Relative humidity|     100.0P|        %RH|2024-11-02 15:30:36|\n",
      "|      Ua|   Relative humidity|     100.0P|        %RH|2024-11-02 15:31:16|\n",
      "|      Ta|     Air temperature|       6.1C|         °C|2024-11-02 15:31:26|\n",
      "|      Pa|        Air pressure|     882.8H|        hPa|2024-11-02 15:31:26|\n",
      "|      Ta|     Air temperature|       6.1C|         °C|2024-11-02 15:31:36|\n",
      "|      Pa|        Air pressure|     882.8H|        hPa|2024-11-02 15:31:36|\n",
      "|      Ta|     Air temperature|       6.2C|         °C|2024-11-02 15:30:06|\n",
      "|      Vr|  3.5 V ref. voltage|     3.636V|          V|2024-11-02 15:31:23|\n",
      "|      Dm|Wind direction av...|       168D|        deg|2024-11-02 15:31:25|\n",
      "|      Sm|  Wind speed average|       3.5M|        m/s|2024-11-02 15:31:25|\n",
      "|      Ua|   Relative humidity|     100.0P|        %RH|2024-11-02 15:31:25|\n",
      "|      Rc|   Rain accumulation|      1.07M|         mm|2024-11-02 15:31:25|\n",
      "|      Rd|       Rain duration|      1800s|          s|2024-11-02 15:31:25|\n",
      "|      Hc|   Hail accumulation|       0.0M|   hits/cm²|2024-11-02 15:31:25|\n",
      "|      Vh|     Heating voltage|      23.9V|          V|2024-11-02 15:31:23|\n",
      "|      Dn|Wind direction mi...|       157D|        deg|2024-11-02 15:30:25|\n",
      "|      Dm|Wind direction av...|       167D|        deg|2024-11-02 15:30:25|\n",
      "|      Dx|Wind direction ma...|       175D|        deg|2024-11-02 15:30:25|\n",
      "|      Sn|  Wind speed minimum|       1.2M|        m/s|2024-11-02 15:30:25|\n",
      "+--------+--------------------+-----------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "variable_unit_mapping = {\n",
    "    'Sn': {'M': 'm/s', 'K': 'km/h', 'S': 'mph', 'N': 'knots'},  # Wind speed minimum\n",
    "    'Sm': {'M': 'm/s', 'K': 'km/h', 'S': 'mph', 'N': 'knots'},  # Wind speed average\n",
    "    'Sx': {'M': 'm/s', 'K': 'km/h', 'S': 'mph', 'N': 'knots'},  # Wind speed maximum\n",
    "    'Dn': {'D': 'deg'},                                         # Wind direction minimum\n",
    "    'Dm': {'D': 'deg'},                                         # Wind direction average\n",
    "    'Dx': {'D': 'deg'},                                         # Wind direction maximum\n",
    "    'Pa': {'H': 'hPa', 'P': 'Pa', 'B': 'bar', 'M': 'mmHg', 'I': 'inHg'},  # Air pressure\n",
    "    'Ta': {'C': '°C', 'F': '°F'},                               # Air temperature\n",
    "    'Tp': {'C': '°C', 'F': '°F'},                               # Internal temperatur\n",
    "    'Ua': {'P': '%RH'},                                         # Relative humidity\n",
    "    'Rc': {'M': 'mm', 'I': 'in'},                               # Rain accumulation\n",
    "    'Rd': {'S': 's'},                                           # Rain duration\n",
    "    'Ri': {'M': 'mm/h', 'I': 'in/h'},                           # Rain intensity\n",
    "    'Rp': {'M': 'mm/h', 'I': 'in/h'},                           # Rain peak intensity \n",
    "    'Hc': {'M': 'hits/cm²', 'I': 'hits/in²', 'H': 'hits'},      # Hail accumulation\n",
    "    'Hd': {'S': 's'},                                           # Hail duration\n",
    "    'Hi': {'M': 'hits/cm²h', 'I': 'hits/in²h', 'H': 'hits/h'},  # Hail intensity \n",
    "    'Hp': {'M': 'hits/cm²h', 'I': 'hits/in²h', 'H': 'hits/h'},  # Hail peak intensity \n",
    "    'Th': {'C': '°C', 'F': '°F' },                              # Heating temperature \n",
    "    'Vh': {'V': 'V', 'N': 'N', 'W': 'W', 'F2':'F2'},            # Heating voltage \n",
    "    'Vs': {'V': 'V'},                                           # Supply voltage\n",
    "    'Vr': {'V': 'V'},                                           # 3.5 V ref. voltage\n",
    "}\n",
    "\n",
    "# Función para mapear las unidades de una variable específica\n",
    "def map_units(variable, unit):\n",
    "    if variable in variable_unit_mapping:\n",
    "        return variable_unit_mapping[variable].get(unit, unit)  # Devuelve la unidad mapeada, o la original si no existe mapeo\n",
    "    return unit\n",
    "\n",
    "# Registrar la UDF\n",
    "map_units_udf = F.udf(map_units, StringType())\n",
    "\n",
    "\n",
    "# Diccionario de variables y sus significados\n",
    "variable_meaning_mapping = {\n",
    "    'Sn': 'Wind speed minimum',\n",
    "    'Sm': 'Wind speed average',\n",
    "    'Sx': 'Wind speed maximum',\n",
    "    'Dn': 'Wind direction minimum',\n",
    "    'Dm': 'Wind direction average',\n",
    "    'Dx': 'Wind direction maximum',\n",
    "    'Pa': 'Air pressure',\n",
    "    'Ta': 'Air temperature',\n",
    "    'Tp': 'Internal temperatur',\n",
    "    'Ua': 'Relative humidity',\n",
    "    'Rc': 'Rain accumulation',\n",
    "    'Rd': 'Rain duration',\n",
    "    'Ri': 'Rain intensity',\n",
    "    'Rp': 'Rain peak intensity', \n",
    "    'Hc': 'Hail accumulation',\n",
    "    'Hd': 'Hail duration',\n",
    "    'Hi': 'Hail intensity',\n",
    "    'Hp': 'Hail peak intensity', \n",
    "    'Th': 'Heating temperature', \n",
    "    'Vh': 'Heating voltage', \n",
    "    'Vs': 'Supply voltage',\n",
    "    'Vr': '3.5 V ref. voltage',\n",
    "}\n",
    "\n",
    "# Función para obtener el significado de una variable específica\n",
    "def get_variable_meaning(variable):\n",
    "    return variable_meaning_mapping.get(variable, \"Unknown variable\")  # Devuelve \"Unknown variable\" si no existe mapeo\n",
    "\n",
    "# Registrar la UDF\n",
    "get_variable_meaning_udf = F.udf(get_variable_meaning, StringType())\n",
    "\n",
    "# Aplicar la función de mapeo para cada fila para obtener el significado de la variable\n",
    "df = df.withColumn(\"nombre_variable\", get_variable_meaning_udf(F.col(\"Variable\")))\n",
    "\n",
    "# Aplicar la función de mapeo para cada fila para obtener la unidad mapeada\n",
    "df = df.withColumn(\"Mapped_Unit\", map_units_udf(F.col(\"Variable\"), F.col(\"Measurement\").substr(-1, 1)))  # Asegúrate de extraer la unidad correctamente de Measurement\n",
    "\n",
    "# Seleccionar las columnas con la unidad mapeada y el nombre de la variable\n",
    "df = df.select(\"Variable\", \"nombre_variable\", \"Measurement\", \"Mapped_Unit\", \"Timestamp\")\n",
    "\n",
    "\n",
    "# Mostrar los datos resultantes\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25219e48-1ed4-4bd4-9474-13714d567bd7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-02T18:51:48.3039161Z",
       "execution_start_time": "2024-11-02T18:51:47.3925824Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "6ccafe9d-3bba-484d-906f-07f75072ff64",
       "queued_time": "2024-11-02T18:51:41.1042991Z",
       "session_id": "6b9a1872-50ac-457d-845a-740201bbd234",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 47,
       "statement_ids": [
        47
       ]
      },
      "text/plain": [
       "StatementMeta(, 6b9a1872-50ac-457d-845a-740201bbd234, 47, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------------------+-----------+-----------+-------------------+\n",
      "|Variable|     nombre_variable|Measurement_Numeric|Measurement|Mapped_Unit|          Timestamp|\n",
      "+--------+--------------------+-------------------+-----------+-----------+-------------------+\n",
      "|      Ta|     Air temperature|                6.1|       6.1C|         °C|2024-11-02 15:30:36|\n",
      "|      Ua|   Relative humidity|              100.0|     100.0P|        %RH|2024-11-02 15:30:36|\n",
      "|      Ua|   Relative humidity|              100.0|     100.0P|        %RH|2024-11-02 15:31:16|\n",
      "|      Ta|     Air temperature|                6.1|       6.1C|         °C|2024-11-02 15:31:26|\n",
      "|      Pa|        Air pressure|              882.8|     882.8H|        hPa|2024-11-02 15:31:26|\n",
      "|      Ta|     Air temperature|                6.1|       6.1C|         °C|2024-11-02 15:31:36|\n",
      "|      Pa|        Air pressure|              882.8|     882.8H|        hPa|2024-11-02 15:31:36|\n",
      "|      Ta|     Air temperature|                6.2|       6.2C|         °C|2024-11-02 15:30:06|\n",
      "|      Vr|  3.5 V ref. voltage|              3.636|     3.636V|          V|2024-11-02 15:31:23|\n",
      "|      Dm|Wind direction av...|                168|       168D|        deg|2024-11-02 15:31:25|\n",
      "|      Sm|  Wind speed average|                3.5|       3.5M|        m/s|2024-11-02 15:31:25|\n",
      "|      Ua|   Relative humidity|              100.0|     100.0P|        %RH|2024-11-02 15:31:25|\n",
      "|      Rc|   Rain accumulation|               1.07|      1.07M|         mm|2024-11-02 15:31:25|\n",
      "|      Rd|       Rain duration|               1800|      1800s|          s|2024-11-02 15:31:25|\n",
      "|      Hc|   Hail accumulation|                0.0|       0.0M|   hits/cm²|2024-11-02 15:31:25|\n",
      "|      Vh|     Heating voltage|               23.9|      23.9V|          V|2024-11-02 15:31:23|\n",
      "|      Dn|Wind direction mi...|                157|       157D|        deg|2024-11-02 15:30:25|\n",
      "|      Dm|Wind direction av...|                167|       167D|        deg|2024-11-02 15:30:25|\n",
      "|      Dx|Wind direction ma...|                175|       175D|        deg|2024-11-02 15:30:25|\n",
      "|      Sn|  Wind speed minimum|                1.2|       1.2M|        m/s|2024-11-02 15:30:25|\n",
      "+--------+--------------------+-------------------+-----------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extraer solo los números de la columna Measurement\n",
    "df = df.withColumn(\"Measurement_Numeric\", F.regexp_extract(F.col(\"Measurement\"), r'(\\d*\\.?\\d+)', 0))\n",
    "\n",
    "# Seleccionar las columnas deseadas\n",
    "df_cleaned = df.select(\"Variable\", \"nombre_variable\",  \"Measurement_Numeric\", \"Measurement\", \"Mapped_Unit\", \"Timestamp\")\n",
    "\n",
    "# Mostrar los datos resultantes\n",
    "df_cleaned.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbf9c3b5-af4c-420a-b13e-b75fd1babf6e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-02T18:51:51.3773564Z",
       "execution_start_time": "2024-11-02T18:51:48.8802354Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "4206e5a6-5ef7-4cba-a384-0c6f222ab28a",
       "queued_time": "2024-11-02T18:51:41.2772072Z",
       "session_id": "6b9a1872-50ac-457d-845a-740201bbd234",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 48,
       "statement_ids": [
        48
       ]
      },
      "text/plain": [
       "StatementMeta(, 6b9a1872-50ac-457d-845a-740201bbd234, 48, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Parquet guardado en Files/silver/datos_silver.parquet\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Ruta a la carpeta y archivo Parquet en la carpeta 'silver'\n",
    "path = \"Files/silver\"  # Ruta a la carpeta 'silver'\n",
    "parquet_file = f\"{path}/datos_silver.parquet\"  # Archivo Parquet\n",
    "\n",
    "# Verificar si la carpeta 'silver' existe, si no, crearla\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Si el archivo parquet ya existe, eliminarlo\n",
    "if os.path.exists(parquet_file):\n",
    "    os.remove(parquet_file)  # Cambié shutil.rmtree por os.remove para eliminar un archivo\n",
    "\n",
    "# Guardar el DataFrame en formato Parquet en la carpeta 'silver'\n",
    "df_cleaned.write.mode(\"overwrite\").parquet(parquet_file)\n",
    "\n",
    "print(f\"Archivo Parquet guardado en {parquet_file}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "0987027a-b74c-44d6-8f03-624f16aa3fa7",
    "default_lakehouse_name": "BronzeWeather",
    "default_lakehouse_workspace_id": "a87d9f4b-81a6-4f9e-b615-804f2459d267",
    "known_lakehouses": [
     {
      "id": "0987027a-b74c-44d6-8f03-624f16aa3fa7"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "es"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
